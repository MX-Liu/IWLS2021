# -*- coding: utf-8 -*-
"""Copy of model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kdgNfANIxUWt8Ky2q7PFlrDKnqoHEYDF
"""

from keras.models import Model
from keras.layers import Input,Dense,Flatten,Dropout,MaxPooling2D
from keras.layers.convolutional import Conv2D
from keras.layers.merge import concatenate
from keras.datasets import cifar10
from keras.utils.np_utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from keras.models import load_model
from keras.layers import ReLU
from keras import backend as K
from keras import constraints
from keras.initializers import RandomUniform
import functools
import tensorflow as tf



def load_dataset():
    # load dataset
    (trainX, trainY), (testX, testY) = cifar10.load_data()
    
    for i in range(50000):
      for x in range(0,16):
          for y in range(0,16):
              for z in range(0,3):
                
                  trainX[i][x][y][z]=trainX[i][2*x][2*y][z]//2
                  if i<testX.shape[0]:
                    testX[i][x][y][z]=testX[i][2*x][2*y][z]//2

                    '''
    
    trainX >>= 1
    
    trainX = np.concatenate((trainX[:, ::2, ::2, :], trainX[:, 1::2, 1::2, :]), axis=0)
    testX = np.concatenate((testX[:, ::2, ::2, :], testX[:, 1::2, 1::2, :]), axis=0)
    trainY = np.concatenate(2 * (trainY, ), axis=0)
    testY = np.concatenate(2 * (testY, ), axis=0)
    
    trainX = trainX[:, ::2, ::2, :]
    testX = testX[:, ::2, ::2, :]
    '''
    trainY = to_categorical(trainY)
    testY = to_categorical(testY)
   
    return trainX, trainY, testX, testY

##needed when modeling fixpoint input performance for each layer
class rounding(tf.keras.layers.Layer):

    def __init__(self):
        super(rounding, self).__init__()


    def call(self, inputs):
        return tf.round(inputs*2)/2
##weight constaint
class fix_4bits(tf.keras.constraints.Constraint):

    def __init__(self):
      pass


    def __call__(self, w):
      

      return tf.round(w*16)/16

#weight constraint (more extreme)
class fixpoint(tf.keras.constraints.Constraint):


  def __init__(self):
    pass

  def __call__(self, w):
    
    #w = tf.where(w > 0.09375 , 0.125, tf.where(w > 0.03125, 0.0625 ,tf.where(w < -0.09375, -0.125 , tf.where(w < -0.03125, -0.0625 , 0) ) ))
    #w = tf.where(w>0.0625,0.125,tf.where(w<-0.0625,-0.125,0))
    w = tf.where(w>0.8,1.0,tf.where(w>0.45,0.5,tf.where(w>0.2,0.25,tf.where(w > 0.09375 , 0.125, tf.where(w > 0.03125, 0.0625 
        ,tf.where(w<-0.8,-1.0,tf.where(w<-0.45,-0.5,tf.where(w<-0.2,-0.25,tf.where(w < -0.09375, -0.125 , tf.where(w < -0.03125, -0.0625 , 0) )) ) )   )))))
   
    return w 
#bias constraint
class fixpoint_b(tf.keras.constraints.Constraint):
 

  def __init__(self):
    pass

  def __call__(self, b):
    b = tf.round(b*4)/4
    return b 


def model(fixpoint,fixpoint_b,view_layer_output,fix_4bits):

  input = Input(shape=(16,16,3))

  initializer = RandomUniform(minval=-0.1 , maxval=0.1)

  #max = MaxPooling2D(pool_size=(2,2),strides=2, padding='valid',name='max1',input_shape=(32,32, 3))(input)

  conv11 = Conv2D(10,(2, 2),strides=2, padding='valid',data_format="channels_last",activation=ReLU(max_value=16,threshold=0)
  ,use_bias=True,kernel_constraint=fixpoint,name='conv11',bias_constraint=fixpoint_b,kernel_initializer=initializer)(input)

  #r1 = rounding()(conv11)


  drop1 = Dropout(0.1)(conv11)

 

  conv21 = Conv2D(18, (2, 2),strides=2,activation=ReLU(max_value=16,threshold=0),use_bias=True
          ,kernel_constraint=fixpoint,name='conv21',bias_constraint=fixpoint_b,kernel_initializer=initializer)(drop1[:,:,:,0:8])

  conv22 = Conv2D(13, (2, 2),strides=2,activation=ReLU(max_value=16,threshold=0),use_bias=True
          ,kernel_constraint=fixpoint,name='conv22',bias_constraint=fixpoint_b,kernel_initializer=initializer)(drop1[:,:,:,4:10])
  
 

  drop21 = Dropout(0.1)(conv21)
  drop22 = Dropout(0.1)(conv22)
  
  flat1 = Flatten()(drop21)

  flat2 = Flatten()(drop22)



  merge_last= concatenate([flat1,flat2])
  
  #r2 = rounding()(merge_last)
  #fixpoint1=fixpoint1()
  dense1 = Dense(16,activation=ReLU(max_value=16,threshold=0),use_bias=True,name='dense1',bias_constraint=fixpoint_b,kernel_constraint=fixpoint)(merge_last)

  #r3 = rounding()(dense1)
  output = Dense(10,activation='softmax',use_bias=True,name='dense',bias_constraint=fixpoint_b,kernel_constraint=fix_4bits)(dense1)
  #output = Dense(10,activation=None,use_bias=True,name='dense',bias_constraint=fixpoint_b,kernel_constraint=fixpoint)(r2)
 
  if view_layer_output==True:
    model = Model(inputs=input,outputs=r3)
  else:
    model = Model(inputs=input,outputs=output)
  model.compile(optimizer = "adam", loss='categorical_crossentropy',metrics=['accuracy'])


  return model  

def train_with_original_data(model,trainX, trainY, testX, testY ):

 
  model.fit(trainX, trainY , batch_size=150, epochs=150, validation_split=0.1)
  _, acc = model.evaluate(testX, testY, verbose=0)
  print('> %.3f' % (acc * 100.0))
  '''
  outputs=[]
  keras_function = K.function([model.input], [model.layer[2].output])
  outputs.append(keras_function([trainX[0], 1]))
  print(outputs)
  '''

def train_with_augmented_data(model,trainX, trainY, testX, testY):

  #trainX, trainY, testX, testY = load_dataset()
  datagen = ImageDataGenerator(
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    validation_split=0.1)
  
  datagen.fit(trainX)
  model.fit(datagen.flow(trainX, trainY, batch_size=200,
         subset='training'), 
          validation_data=datagen.flow(trainX, trainY,
         batch_size=15, subset='validation'), epochs=30)

  _, acc = model.evaluate(testX, testY, verbose=0)
  print('> %.3f' % (acc * 100.0))


#Train with floating point

fixpoint = fixpoint()
fixpoint_b = fixpoint_b()
fix_4bits=fix_4bits()
trainX, trainY, testX, testY = load_dataset()

model2 = model(fixpoint,fixpoint_b,False,fix_4bits)
model2.summary()
model2.load_weights(("/content/gdrive/MyDrive/test2/model2dense_5602_b6")


model4 = model(fixpoint,fixpoint_b,True,fun)




train_with_original_data(model2,trainX[:,0:16,0:16,:], trainY, testX[:,0:16,0:16,:], testY)
train_with_augmented_data(model3,trainX[:,0:16,0:16,:], trainY, testX[:,0:16,0:16,:], testY )

model2.save_weights("/content/gdrive/MyDrive/test2/model2dense_16_5724",save_format='tf')
model2.save("/content/gdrive/MyDrive/test2/model2dense_16_5724",save_format='tf')

#mount googledrive
from google.colab import drive
from google.colab import files
 
import os


drive.mount('/content/gdrive/',force_remount=True)

#trainX, trainY, testX, testY = load_dataset()
_, acc = model2.evaluate(testX[:,0:16,0:16,], testY, verbose=0)
print('> %.3f' % (acc * 100.0))

##view weights

def view_weights(model):
  for layer in model.layers: 
   
    print(layer.name)
    for element in layer.get_weights():
      print(element)
     
    
##save weights
def save_as_np(model):
  for layer in model.layers:
    if(layer.name=="dense"):
      weight,bias=layer.get_weights()
      np.save("/content/gdrive/MyDrive/test2/weight_array_dense2/dense_weight.npy", weight)
      np.save("/content/gdrive/MyDrive/test2/weight_array_dense2/dense_bias.npy", bias)

##find range
def find_min_max(model):
  max=0
  min=10
  for layer in model.layers:
    if(layer.name=="dense"):
      weight,bias=layer.get_weights()
      for i in weight:
        for j in i:
          if j<min:
            min=j
          if j>max:
            max=j
      print(f"max:{max}")
      print(f"min:{min}")


#save_as_np(model2)
view_weights(model2)
find_min_max(model2)

##for debug

#inputShape[0]:h
#inputShape[1]:w
#inputShape[2]:c
def first_to_last(test,inputShape):
  result=test.copy()
  for  ho in range(inputShape[0]):
    for wo in range(inputShape[1]):
      for co in range(inputShape[2]):
        in_index = co*inputShape[0]*inputShape[1]+ho*inputShape[1]+wo
        out_index = ho*inputShape[1]*inputShape[2]+wo*inputShape[2]+co
        result[out_index] = test[in_index]

  return result

def last_to_first(test,inputShape):
  result=test.copy()
  for co in range(inputShape[2]):
    for ho in range(inputShape[0]):
      for wo in range(inputShape[1]):
        in_index = ho*inputShape[1]*inputShape[2]+wo*inputShape[2]+co
        out_index = co*inputShape[0]*inputShape[1]+ho*inputShape[1]+wo
        result[out_index] = test[in_index]

  return result

###for debug

trainX, trainY, _ = load_dataset()
for file_num in range(2000,3500):
  fout = open("/content/gdrive/MyDrive/data2000_3000/test"+str(file_num )+".txt","w")
  a=np.array(testX[file_num,:,:,:])
  a=a.flatten()
  a=last_to_first(a,[32,32,3])

  for j in range(len(a)): 
    b=format(a[j], "b")
    fout.write(b)
    fout.write("\n")


#np.argmax(b)

##for debug

f = open("/content/gdrive/MyDrive/test_result/final2.txt", 'r')

content = f.readlines()
counter=2000

correct=0
for line in content:
  
  print(f"case:{counter}\n")
  
  p=model2.predict(trainX[counter:counter+1,0:16,0:16,:])
  print("model3 predict:")
  print(p)
  
  #print(np.argmax(testY[counter]))


  for i in range(10):
    if line[i]=='1':
      
      print("hard ware :")
      print(i)
      print("golden data:")
      print( testY[counter] )

      
      if i==testY[counter]:
        correct=correct+1
        
      
  counter=counter+1    
       
print(f"number of data:{counter}")
print(f"correct:{correct}")